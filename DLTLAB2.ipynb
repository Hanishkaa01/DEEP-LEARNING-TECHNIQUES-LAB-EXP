{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vy_G34N6tLYk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data, iris.target   # Features and labels\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Convert to tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "R2d55P8Wt0QG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IrisNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IrisNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 16)   # 4 features -> hidden layer\n",
        "        self.fc2 = nn.Linear(16, 12)\n",
        "        self.fc3 = nn.Linear(12, 3)   # 3 classes\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = IrisNet()\n"
      ],
      "metadata": {
        "id": "aIKFqSlot6Xl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n"
      ],
      "metadata": {
        "id": "aVPofPoqt9Il"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYfnMrMvuAxZ",
        "outputId": "65b25968-8c89-47d2-94b5-9eb744c61ed9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.7252\n",
            "Epoch [20/100], Loss: 0.4054\n",
            "Epoch [30/100], Loss: 0.3065\n",
            "Epoch [40/100], Loss: 0.1959\n",
            "Epoch [50/100], Loss: 0.0995\n",
            "Epoch [60/100], Loss: 0.0642\n",
            "Epoch [70/100], Loss: 0.0520\n",
            "Epoch [80/100], Loss: 0.0461\n",
            "Epoch [90/100], Loss: 0.0429\n",
            "Epoch [100/100], Loss: 0.0414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(X_test)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
        "\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nelhr2iXuEm9",
        "outputId": "a7652430-351a-4c87-e030-3186de4cbab3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# STEP 1: Import Libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# STEP 2: Load and Preprocess Data\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data, iris.target   # 150 samples, 4 features, 3 classes\n",
        "\n",
        "# Split into Train, Validation, Test\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.2, random_state=42, stratify=y_train_full\n",
        ")\n",
        "\n",
        "# Standardize (important for NN training!)\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_val = sc.transform(X_val)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_val = torch.tensor(y_val, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "\n",
        "# STEP 3: Define Model (with Dropout)\n",
        "\n",
        "class IrisNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IrisNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(8, 3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)  # 30% neurons off during training\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = IrisNet()\n",
        "\n",
        "\n",
        "# STEP 4: Loss & Optimizer (with Regularization)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)  # L2 regularization\n",
        "\n",
        "\n",
        "# STEP 5: Training with Early Stopping\n",
        "epochs = 200\n",
        "best_val_loss = float(\"inf\")\n",
        "patience, patience_counter = 20, 0  # Early stopping patience\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val)\n",
        "        val_loss = criterion(val_outputs, y_val)\n",
        "\n",
        "    # Early Stopping Check\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        best_model_state = model.state_dict()  # Save best model\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"⏹ Early stopping at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(best_model_state)\n",
        "\n",
        "# STEP 6: Final Evaluation\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test)\n",
        "    _, predicted = torch.max(test_outputs, 1)\n",
        "    accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
        "\n",
        "print(f\"Final Test Accuracy: {accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-guA9XKucGy",
        "outputId": "e6c7191f-48ae-4ebc-9b45-cf6239ffb13b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Train Loss: 0.8535, Val Loss: 0.7457\n",
            "Epoch 20, Train Loss: 0.5443, Val Loss: 0.4481\n",
            "Epoch 30, Train Loss: 0.4618, Val Loss: 0.2981\n",
            "Epoch 40, Train Loss: 0.3104, Val Loss: 0.2388\n",
            "Epoch 50, Train Loss: 0.3427, Val Loss: 0.2064\n",
            "Epoch 60, Train Loss: 0.2101, Val Loss: 0.1624\n",
            "Epoch 70, Train Loss: 0.1467, Val Loss: 0.1537\n",
            "Epoch 80, Train Loss: 0.1689, Val Loss: 0.1364\n",
            "Epoch 90, Train Loss: 0.1518, Val Loss: 0.1736\n",
            "Epoch 100, Train Loss: 0.1734, Val Loss: 0.1436\n",
            "⏹ Early stopping at epoch 102\n",
            "Final Test Accuracy: 96.67%\n"
          ]
        }
      ]
    }
  ]
}